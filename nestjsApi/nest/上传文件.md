### Express 使用 multer 实现文件上传
```JS
// 安装 npm install multer

const express = require('express');
const multer = require('multer');

const app = express();
// 设置存储文件的目录和文件名
// 创建一个存储文件的目录和文件名的配置对象
const storage = multer.diskStorage({
    destination: function(req, file, cb) {
        cb(null, 'uploads/'); // 文件存放的目录
    },
    filename: function(req, file, cb) {
        cb(null, Date.now() + '-' + file.originalname); // 保存原始文件名
    }
});

const upload = multer({
    storage: storage
})

// upload.single('file') 处理单个文件上传请求
// upload.array('file') 处理多个文件上传请求
app.post('/upload', upload.array('file'), function(req, res) {
    res.send('success');
})

app.listen(3000, function() {
    console.log('启动');
});
```

### Nest 如何使用 multer 实现文件上传
```TS
// 安装 multer 和 @nestjs/platform-express
// npm install multer @nestjs/platform-express

import { Module } from '@nestjs/common';
import { MulterModule } from '@nestjs/platform-express';
import { diskStorage } from 'multer';
import { editFileName, imageFileFilter } from './file.utils';
import { FileController } from './file.controller';

@Module({
    imports: [
        MulterModule.register({
            storage: diskStorage({
                destination: './uploads',
                filename: editFileName
            })
        })
    ],
    controllers: [FileController]
})
export class FileModule {}

// 然后在控制器中使用 @UseInterceptors(FileInterceptor('file', { dest: 'name' // name 上传的目录文件 , storage: "" 可以指定文件名目录  })) 注解来处理文件上传
import { Controller, Post, UploadedFile, UseInterceptors } from '@nestjs/common';
import { FileInterceptor } from '@nestjs/platform-express';

@Controller('file')
export class FileController {
    @Post('upload')
    @UseInterceptors(FileInterceptor('file'))
    uploadFile(@UploadedFile() file) {
        console.log(file);
        return { success: true };
    }
}

// 上面的代码中，我们在 upload 路径下使用了 @Post 和 @UseInterceptors 注解来接受文件上传请求，并使用 @UploadedFile() 注解注入上传的文件对象。在示例中，我们将文件对象输出到控制台，并且返回结果致 success: true 的 JSON 格式响应
// 另外注意，在使用 Multer 时还需要创建一个 file.utils.ts 的文件，并且定义 editFileName 和 imageFileFilter 方法。这些方法用于修改并过滤上传的文件
// file.utils.ts
import { extname } from 'path';

export const editFileName = (req, file, callback) => {
    const name = file.originalname.split('.')[0];
    const fileExtName = extname(file.originalname);
    const randomName = Array(4)
        .fill(null)
        .map(() => Math.round(Math.random() * 16).toString(16))
        .join('');
    callback(null, `${name}-${randomName}${fileExtName}`);
};

export const imageFileFilter = (req, file, callback) => {
    if (!file.originalname.match(/\.(jpg|jpeg|png|gif)$/)) {
        return callback(new Error('Only image files are allowed!'), false);
    }
    callback(null, true);
};
```

### Express 大文件分片上传
```TS
// html 部分
<input type="file" id="file">
<button onClick="handleUpload">提交</button>
<script>
const FILE_CHUNK_SIZE = 1024 * 1024; // 1MB
async function handleUpload() {
    const file = document.getElementById('file').files[0];
    const start = 0;
    let currentChunk = 0;

    while(start + currentChunk * FILE_CHUNK_SIZE < file.size) {
        const chunk = file.slice(
            start + currentChunk * FILE_CHUNK_SIZE,
            start + (currentChunk + 1) * FILE_CHUNK_SIZE
        );
        const formData = new FormData();
        formData.append('file', chunk, file.name, `${currentChunk}-${file.name}`);
        formData.append('chunkNumber', currentChunk + 1); // 第几个
        formData.append('totalChunks', Math.ceil(file.size / FILE_CHUNK_SIZE)); // 总数量

        await fetch('/upload', {
            method: 'POST',
            body: formData
        });

        currentChunk++;
    };

    await fetch('/merge', {
        method: 'POST',
        body: JSON.stringify({
            name: file.name,
            type: file.type,
            size: file.size
        })
    })
}
</script>

// node 部分
const express = require('express');
const multer = require('multer');
const fs = require('fs');
const app = express();

const UPLOAD_DIR = './temp'; // 文件上传时存储的临时目录
if(!fs.existsSync(UPLOAD_DIR)) fs.mkdirSync(UPLOAD_DIR);

// 创建 Multer 实例
const upload = multer({
    dest: UPLOAD_DIR
})

// 处理上传分块
app.post('/upload', upload.single('file'), async (req, res) => {
    const { filename, chunkNumber, totalChunks } = req.body;
    const chunkDir = `${UPLOAD_DIR}/${filename}`;
    // 如果该文件片段没有上传过，就将其保存到该文件片段对应的目录下，否则不做处理。
    if (!fs.existsSync(chunkDir)) {
        fs.mkdirSync(chunkDir);
    }
    fs.renameSync(req.file.path, `${chunkDir}/${chunkNumber}`);
    res.status(200).send({ msg: 'Upload Success' });
})

// 处理合并请求
app.post('/merge', async (req, res) => {
    const { name, type, size } = req.body;

    // 获取存储该文件的集合，里面包含该文件的所有块的名称
    const chunksDir = `${UPLOAD_DIR}/${name}`;
    const chunks = fs.readdirSync(chunksDir);
    // 根据块内各个块的名称，对其按块序号进行排序，然后获取其对应的路径信息并组合成一个数组
    // 之后使用 stream 读写流将其合并到目标文件中，最后删除临时文件和块文件
    chunks.sort((a, b) => a.split('-')[0] - b.split('-')[0]);

    const ws = fs.createWriteStream(`${chunksDir}/${chunks[i]}`);
    for (let i = 0; i < chunks.length; i++) {
        const rs = fs.createReadStream(`${chunksDir}/${chunks[i]}`);
        rs.pipe(ws, { end: false });
        rs.on('end', () => {
            fs.unlinkSync(`${chunksDir}/${chunks[i]}`);
        });
    }

    ws.on('close', () => {
        fs.rmdirSync(chunksDir);
        res.status(200).send('Merge Success');
    });
})
app.listen(3000, () => {
  console.log('Server started on http://localhost:3000');
});
```

### Nest 如何使用 multer 实现大文件分片上传
需要用到一个额外的包 multer-s3-transform。该包主要是增加了对 S3 存储的支持，同时支持文件、大小、数量等方面的限制
npm install multer-s3-transform
```TS
import { Body, Controller, Post, UploadedFiles, UseInterceptors } from '@nestjs/common';
import * as multer from 'multer';
import { AwsService } from 'src/aws/aws.service';
import { FilesInterceptor } from '@nestjs/platform-express';
import { MulterS3Transform } from 'multer-s3-transform';

@Controller('file')
export class FileController {
    constructor(private readonly awsService: AwsService) {}

    @Post('upload')
    @UseInterceptors(
        FilesInterceptor('files', 10, {
            storage: new MulterS3Transform({
                s3: this.awsService.s3,
                bucket: 'your-bucket-name',
                shouldTransform: true,
                transforms: [
                    {
                        id: 'original',
                        key: (req, file, cb) => {
                            console.log(file);
                            cb(null, file.originalname);
                        },
                        transform: (req, file, cb) => {
                            console.log(file);
                            cb(null, {
                                acl: 'public-read',
                                metadata: { fieldName: file.fieldname },
                            });
                        }
                    }
                ]
            })
        })
    )

    async uploadFile(@UploadedFiles() files) {
        console.log(files);
    }
}
// 这里使用 FilesInterceptor 来接收上传文件，并且使用 MulterS3Transform 这个类来做存储到 S3 上，同时也在上面设置了一些 S3 相关的配置，如上传的 bucket、是否需要分片、一些转换等等
// 我们使用了 shouldTransform: true 来强制启用分片上传，可以有效提高大文件上传的速度和稳定性。上传完成后会将文件信息返回到 uploadFile 方法中。
// 前端页面方面，需要引入一个 chunkUpload.js 的 JS 文件，这个文件负责将大文件拆分为多个块来上传
<div class="row">
    <div class="col-sm-12 col-md-12 col-lg-12 text-center">
        <h1>File Upload with Multer and NestJS</h1>
        <form
            id="uploadFile"
            action="http://localhost:3000/file/upload"
            method="post"
            enctype="multipart/form-data"
        >
            <input type="hidden" name="key" value="" />
            <input type="file" name="files" class="form-control-file" multiple />
            <button type="button" class="btn btn-primary mt-3" id="submit-btn">
                Upload
            </button>
        </form>
        <div class="progress mt-3" style="display: none;">
            <div
                class="progress-bar progress-bar-striped progress-bar-animated"
                id="progress-bar"
                style="width: 0%"
            ></div>
        </div>
    </div>
</div>

<script src="js/chunkUpload.js"></script>
<script>
    chunkUpload(
        'submit-btn',
        'uploadFile',
        {
            multiple: false,
            maxSize: 1024 * 1024 * 10,
            chunkSize: 1024 * 1024,
            parallel: 1,
            resume: false,
        },
        function (data, el) {
            console.log(data);
            var s3Key = data.files[0].transforms[0].location;
            document.querySelector("input[name='key']").value = s3Key;
            document.querySelector("#progress-bar").style.width = "100%";
            alert("File uploaded successfully.");
        },
        function (progress) {
            if (progress) {
                var percentage = ((progress.loaded / progress.total) * 100).toFixed(2);
                document.querySelector("#progress-bar").style.width = percentage + "%";
            }
        }
    );
</script>

// chunkUpload.js
function chunkUpload(buttonId, formId, options, onSuccess, onProgress) {
  var ex, idx, s3data, state, xhr, useResume;
  idx = -1;
  xhr = null;
  s3data = null;
  state = {
    uploadId: "",
    chunks: null,is
    parallel: options.parallel || 1,
    chunkSize: options.chunkSize || 1024 * 1024, // in bytes
    totalSize: 0,
    loaded: 0,
    file: null,
    url: "",
    error: "",
    expired: false,
  };
  useResume = options.resume || false;

  function toArray(list) {
    return Array.prototype.slice.call(list);
  }

  function deferred() {
    var defer = {
      promise: undefined,
      resolve: undefined,
      reject: undefined,
    };
    defer.promise = new Promise(function (resolve, reject) {
      defer.resolve = resolve;
      defer.reject = reject;
    });
    return defer;
  }

  // fileName is optional and is only used to generate a unique boundary
  function createFormData(file, part) {
    var formData = new FormData();
    var boundary = "xxxxxxxxxx" + (part ? part : "") + Math.random().toString().substring(2, 10);
    var chunk = file.slice(state.chunkSize * (part - 1), state.chunkSize * part);

    formData.append("key", document.querySelector("input[name='key']").value);
    formData.append("Content-Type", file.type);
    formData.append("Content-Length", chunk.size);
    formData.append("Expect", "");
    formData.append("Content-Disposition", "inline; filename='" + encodeURIComponent(file.name) + "'; filename*=UTF-8''" + encodeURIComponent(file.name));

    formData.append("file", chunk, Math.random().toString().substring(2, 10));
    formData.append("AWSAccessKeyId", s3data.key);
    formData.append("policy", s3data.policy);
    formData.append("signature", s3data.signature);

    xhr.setRequestHeader("Content-type", "multipart/form-data; boundary=" + boundary);

    return { formData: formData, boundary: boundary };
  }

  function batch(file, _s3data, onProgress) {
    var chunkSize = state.chunkSize,
      chunks, totalSize;

    totalSize = file.size;
    idx = -1;
    chunks = Array.from({ length: Math.ceil(file.size / chunkSize) }, function () {
      idx += 1;
      var chunk = file.slice(idx * chunkSize, Math.min((idx + 1) * chunkSize, totalSize));
      return {
        status: "pending",
        file: chunk,
        xhr: null,
        part: idx + 1,
      };
    });

    state.chunks = chunks;
    state.totalSize = totalSize;
    state.file = file;

    if (_s3data && _s3data.key && _s3data.policy && _s3data.signature) {
      state.url = "https://" + _s3data.bucket + ".s3.amazonaws.com";
      s3data = _s3data;
    }

    var inProgress = 0;
    var getNextChunk = function () {
      if (idx === chunks.length - 1 && chunks[idx].status === "done") {
        return Promise.resolve();
      }
      if (idx === chunks.length - 1 && chunks[idx].status !== "done") {
        chunks = chunks.slice(0, chunks.length - 1);
      }

      while (inProgress < state.parallel) {
        idx += 1;
        if (idx >= chunks.length) {
          break;
        }
        if (chunks[idx].status !== "done" || useResume) {
          inProgress += 1;
          chunks[idx].status = "uploading";
          chunks[idx].prom = upload(chunks[idx], onProgress).then(function () {
            inProgress--;
            return getNextChunk();
          });
        }
      }

      return Promise.all(chunks.map(function (chunk) {
        return chunk.prom;
      }));
    };

    getNextChunk()
      .then(function () {
        if (chunks.every(function (c) {
          return c.status === "done";
        })) {
          onSuccess(state, document.getElementById(buttonId));
        }
      })
      .catch(function (e) {
        state.error = "Upload failed: " + e.message;
      });
  }

  function upload(chunk, onProgress) {
    var defer = deferred();
    var url = state.url;
    xhr = new XMLHttpRequest();
    xhr.onreadystatechange = function () {
      if (xhr.readyState === 4) {
        if (xhr.status >= 200 && xhr.status < 300) {
          s3data = Object.assign({}, s3data, { location: xhr.responseXML.getElementsByTagName("Location")[0].childNodes[0].nodeValue });
          chunk.status = "done";
          state.loaded += chunk.file.size;
          onProgress({ loaded: state.loaded, total: state.totalSize }, document.getElementById(buttonId));
          defer.resolve();
        } else {
          defer.reject(Error("Server returned HTTP status " + xhr.status + " " + xhr.statusText));
        }
      }
    };
    xhr.open("POST", url, true);

    var formData = createFormData(state.file, chunk.part);
    xhr.withCredentials = false;
    xhr.send(formData.formData);

    chunk.xhr = xhr;
    return defer.promise;
  }

  function initialize(file) {
    if (s3data && s3data.key && s3data.policy && s3data.signature) {
      var start = Date.now();
      Aws.config.update({
        accessKeyId: s3data.key,
        secretAccessKey: s3data.secret,
        signatureVersion: "v4",
        region: s3data.region,
      });
      var s3 = new Aws.S3({
        computeChecksums: true,
        signatureVersion: "v4",
      });
      var params = {
        Bucket: s3data.bucket,
        Key: file.name,
        ContentType: file.type,
      };
      s3.createMultipartUpload(params, function (err, results) {
        if (err) {
          throw new Error("Error while creating multipart upload signature");
        }
        s3data.uploadId = results.UploadId;
        state.uploadId = results.UploadId;
        console.log("Initialization Time:", Date.now() - start, "ms");
        batch(file, s3data, onProgress);
      });
    }
  }

  function onButtonClick(e) {
    var files = document.getElementById(formId).elements["files"].files;
    if (files && files.length > 0) {
      state.error = "";
      var file = files[0];

      // If there is an overwritten state we try to resume chunks already uploaded
      if (state.chunks) {
        options.resume = useResume = true;
      }

      initialize(file);
    } else {
      alert("Please select a file");
    }
    e.stopPropagation();
    e.preventDefault();
    return false;
  }

  var button = document.getElementById(buttonId);
  if (button) {
    button.removeAttribute("disabled");
    button.addEventListener("click", onButtonClick);
  } else {
    console.warn("button with id", buttonId, "not found on page");
  }
} 
```

###
```JS
const multer = require('multer');
const storage = multer.diskStorage({
  destination: function (req, file, cb) {
    cb(null, 'uploads/') // 设置上传文件存储目录
  },
  filename: function(req, file, cb) {
    cb(null, Date.now() + '-' + file.originalname); // 设置上传文件名
  }
})
const upload = multer({storage: storage});

// 上传文件
app.post('/upload', upload.single('file'), function(req, res) {
  res.send('文件上传成功');
})

```

